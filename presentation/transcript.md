Transcript of the presentation
==============================

Hi

I'm Olivier Pieters, PhD researcher at Ghent University and ILVO. Today I will give a keynote on our recent work regarding the development of a framework to compare plant models.

My main research focusses on investigating the dynamics of plants for computing. Plants are complex and dynamic systems, and we would like to use them as computing resources for plant-related tasks. An interesting first step towards this is to look at plant models since their goal is to model plants in simulation. The main conceptualisation of this framework stems from this background.

Comparing plant models is both relevant for model developers and users. Developers can get an idea of the memory capacity and non-linear modelling behaviour of their models. While users can compare different models to find the most suitable one for their application. However, comparing models is not a trivial task. There is no common modelling paradigm or goal. Different models can have widely different internals and modelling scope, from very broad models like Aquacrop to very specific ones like FSPM Soybean.

Instead of comparing the internals of models, we investigate the input-output relationships. To this end, we use an alternative computing paradigm named reservoir computing. Reservoir computing treats the model as a black box, thus alleviating the problem of very different internals.

Generally speaking, reservoir computing works as follows: a complex system with memory and non-linearity is driven by one or more inputs, represented as green nodes in the figure. These driving signals excite the reservoir, whose state variables are depicted using orange nodes. The interconnectivity which is shown using arcs, represents the internal dependence of the states upon each epoch.  The states are partially or fully observed and  combined using linear regression to obtain one or more outputs.  

It is not necessary to know all states. The only requirement is that part of them are observable. The training of the regressor which computes the output task is the only step that requires training. As a result, reservoir computing is very efficient and easy to optimise using well understood techniques from linear regression.

Since this might all sound a bit vague and abstract, I will illustrate this framework with two examples. 

One of the very first real-world implementations of reservoir computing was this water-bucket classifier by Fernando et al. They performed speech recognition to distinguish between the sounds one and zero with a water bucket. First, an audio sequence is converted to motor stimuli for motors A and B. These motors then actuate rods that create a wave pattern in the bucket. Next, a camera observes these waves. Finally, the resulting pixel values are used to classify the speech pattern as either one or zero. In this case, the inputs are the stimuli, the reservoir is the bucket which is oberved using a webcam and the output target is the classification.

A second example is from compliant robotics. It aims to solve some of the problems with their rigid counterparts. Rigid robots are already heavility used in the automotive industry. But, compliant robots are more versatile and possess a greater capacity to deal with different environments. Additionally, they can deal better with changing body properties such as  wear and tear. Compliant robots are also more energy-efficient, safer for humans and less costly. The drawback is that they are typically more difficult to control than rigid robots. Researches try to tackle this using reservoir computing, thus implementing also adaptive controllers. In this example, springs located on the feet of the robot create compliance. The state of the spring system is read using hall sensors, also located on the robot's feet. These sensor readouts are processed in the controller and combined to move the robot towards its destination. The body is essentially part of the control. This can help in environments with varying friction forces and obstacles.

Going back to the conceptual diagram of reservoir computing, we see that the forces on the leg of the robot and rod/water interaction from the input of the reservoirs. These reservoirs then transform these signals using their complex dynamics and memory. In the case of the robot, these are the springs. While in the first example the bucket is used as reservoir. Finally, the sensor readout is combined to achieve the goal: movement of the robot from A to B and speech classification between one and zero in the first example.

We propose to apply the framework of reservoir computing to plant models, since there is clearly some similarity. Inherently, plant models are composed of different reservoirs or submodels. These submodels have inputs derived from environmental vectors or other submodels. Their output is thus a complex, delayed transformation of the input data, similar to a reservoir. The observed outputs can be combined to predict a certain benchmark task, derived from the input.

This benchmark task has four different requirements. First, it must have some relationship to the model or at least the input. Second, it should also allow us to assess the memory capacity of the model. Third, the same applies to the non-linearity. This implicates that it needs two parameters that tweak its non-linear and memory properties. Finally, we also need a uniform metric to compare different models or parts of the same model.

We propose to use a scaled tangent hyperbolic to obtain non-linear behaviour and a linear filter for the memory assessment. The choice of the parameter beta is to make the sum of filter coefficients h  smaller than one. As a result, it is guaranteed that the signals will eventually die out and that there is no divergent behaviour that leads to instability due to the feedback in y.

A graphical representation of the linear filter h is depicted below for a value of 11 for d, resulting in a peak at the 6th coefficient. The feedback quickly dies out, thus guaranteeing a very locallised effect.

The effect of the nonlinearity parameter alpha is depicted in the top figure. Low values of alpha correspond to very linear behaviour, while large values saturate the output. To visualise the delay effect, we applied a slow pulse to the input. For low values of d, this corresponds to a delayed pulse, while large values create a damped oscillation. This oscillation is due to the negative feedback and the wide filter window. If it is wider than the pulse width, an oscillation is created. Note that due to the choice of beta, the oscillation slowly dies out. A larger value of beta will increase the oscillation, while a smaller value will dampen it more quickly.

Now that we have established a bechmark, we still need a metric to compare the benchmark target to the prediction obtained using the regressor. Normalised mean Squared Error or NMSE is a good candidate. It is similar to MSE, but has the advantage that it avoids bias to slow varying signals and is normalised. Only values between 0 and 1 are interesting. 0 corresponds to a perfect prediction, while 1 corresponds to the mean prediction, clearly the baseline.

The dataflow and regression model are depicted in this datagram. First, all input and output data of the plant model is collected from one or more files into a table. The benchmark is then computed form the input data for a certain alpha and delay value. Next, the data in this table is then split in 60% train data and 40% test data. The test data is used to evaluate the final performance. The training data is used to optimise the linear regression that is fit to the benchmark. The regression model consists of three parts. First, a standard scaler transforms the input data to unit variance and zero mean, follwed by a PCA block that reduces the dimensionality of the input and finally a LASSO regressor. The advantage of LASSO over classical least squares regression is that it will further reduce the dimensionality due to the L1-norm used in the cost function. The final NMSE score is computed from the optimised regressor and test data.  

To visualise the effect of the variation of the two parameters, we use this matrix plot. The lower-left corner is the baseline, corresponding to the easiest benchmark task. Along the horizontal axis, the delay is increased, while the nonlinearity is increased along the vertical axis. Overall, the more one moves to the upper right corner, the more difficult the task becomes. Since alpha is varied logarithmically, we depict log alpha on the y-axis.

This concludes the theoretical description of our framework.

As an example, we applied this framework to WheatFSPM, a model developed for wheat at INRAe by Barillot et al. This is a complex system that utilises several submodels to compute for instance carbon-nitrogen relationships, 3D-structure, biomass and green area, and photosynthesis and respiration. The inputs of the model are the initial conditions, weather data and soil nitrogen.

The model consists of serveral submodels from which 6 reservoirs were identified, summarized in this table. Most groups speak for themselves so we will not go into further detail for each of these groups.

We trained 5 benchmark tasks on each of these reservoirs, resulting in 30 plots summarised in this figure. The darker the blue, the better the performance on this specific benchmark combination. Clearly, some reservoirs have better performance than others. The performance is also not evenly spread among the different tasks. For instance, the photosynthesis and respiration reservoir is good at predicting air temperature-related tasks, while others have low performance. The same hold for the proteins reservoir.

The energy reservoir (E) on the other hand, is better at predicting the four other tasks. It displays good performance for PAR and soil temperature, and low performance for relative humidity (RH) and wind speed (wind). Clearly, RH and wind are more difficult tasks. The same applies to the nitrogen and structure reservoirs. The cytokinin reservoir has low performance for all tasks. Clearly this reservoir has limited memory and non-linear modelling behaviour.

The previous figure showed the results of a simulation with one plant. The current figure displays the result of a simulation with 10 plants, with a different architecture, imperfect sowing densities and slightly different initial conditions per plant. Clearly, some results are the same as in the previous figure, while others are very different. The nitrogen and structure reservoirs' results are similar to those in the previous figure. Decreased performance is observed of photo and energy. This highlights that the benchmark might still maybe still overly dependent on minor alterations in the configuration.

To summarise, we applied reservoir computing to plant models and want to ultimately apply this to actual plants. A benchmark task was designed with variable memory and non-linear properties, which enables users to compare plant models given the same input sequence.

All data and code that lead to this presentation are available on GitHub at the link displayed in this video, as are my contact details. For questions and more information, don't hesitate to contact me.
